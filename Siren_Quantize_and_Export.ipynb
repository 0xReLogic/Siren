{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Siren: Baseline Model Training, Quantization, and ONNX Export\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook covers the complete pipeline using the Hugging Face Optimum library for robust export.\\n\",\n",
    "    \"1.  **Setup**: Install dependencies, including Optimum.\\n\",\n",
    "    \"2.  **Training**: Fine-tune a DistilBERT model on the dataset.\\n\",\n",
    "    \"3.  **ONNX Export & Quantization**: Convert the model to ONNX and apply dynamic quantization simultaneously.\\n\",\n",
    "    \"4.  **Verification**: Load the ONNX model and test it.\\n\",\n",
    "    \"5.  **Download**: Download the final quantized model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Uninstall potentially conflicting libraries first\\n\",\n",
    "    \"!pip uninstall -y torchvision torchaudio\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Install and upgrade the libraries we need, including Optimum\\n\",\n",
    "    \"!pip install --upgrade transformers pandas torch\\n\",\n",
    "    \"!pip install --upgrade onnx onnxruntime\\n\",\n",
    "    \"!pip install --upgrade optimum[onnxruntime]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Upload the dummy_data.csv file\\n\",\n",
    "    \"from google.colab import files\\n\",\n",
    "    \"\\n\",\n",
    "    \"uploaded = files.upload()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for fn in uploaded.keys():\\n\",\n",
    "    \"  print(f'User uploaded file \\\"{fn}\\\" with length {len(uploaded[fn])} bytes')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Model Training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from torch.utils.data import Dataset, DataLoader\\n\",\n",
    "    \"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\\n\",\n",
    "    \"from torch.optim import AdamW\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"\\n\",\n",
    "    \"def train_baseline_model(file_path):\\n\",\n",
    "    \"    # Load Data\\n\",\n",
    "    \"    df = pd.read_csv(file_path)\\n\",\n",
    "    \"    # Use the correct column names: 'text' and 'label'\\n\",\n",
    "    \"    train_texts, val_texts, train_labels, val_labels = train_test_split(\\n\",\n",
    "    \"        df['text'], df['label'], test_size=0.2, random_state=42\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Tokenizer\\n\",\n",
    "    \"    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    class PhishingDataset(Dataset):\\n\",\n",
    "    \"        def __init__(self, encodings, labels):\\n\",\n",
    "    \"            self.encodings = encodings\\n\",\n",
    "    \"            self.labels = labels\\n\",\n",
    "    \"\\n\",\n",
    "    \"        def __getitem__(self, idx):\\n\",\n",
    "    \"            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\\n\",\n",
    "    \"            item['labels'] = torch.tensor(self.labels[idx])\\n\",\n",
    "    \"            return item\\n\",\n",
    "    \"\\n\",\n",
    "    \"        def __len__(self):\\n\",\n",
    "    \"            return len(self.labels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\\n\",\n",
    "    \"    val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    train_dataset = PhishingDataset(train_encodings, list(train_labels))\\n\",\n",
    "    \"    val_dataset = PhishingDataset(val_encodings, list(val_labels))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Model\\n\",\n",
    "    \"    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\\n\",\n",
    "    \"    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\n\",\n",
    "    \"    model.to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Training\\n\",\n",
    "    \"    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\\n\",\n",
    "    \"    optimizer = AdamW(model.parameters(), lr=5e-5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    model.train()\\n\",\n",
    "    \"    for epoch in range(3):  # 3 epochs for fine-tuning\\n\",\n",
    "    \"        for batch in train_loader:\\n\",\n",
    "    \"            optimizer.zero_grad()\\n\",\n",
    "    \"            input_ids = batch['input_ids'].to(device)\\n\",\n",
    "    \"            attention_mask = batch['attention_mask'].to(device)\\n\",\n",
    "    \"            labels = batch['labels'].to(device)\\n\",\n",
    "    \"            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\\n\",\n",
    "    \"            loss = outputs.loss\\n\",\n",
    "    \"            loss.backward()\\n\",\n",
    "    \"            optimizer.step()\\n\",\n",
    "    \"        print(f'Epoch {epoch+1} | Loss: {loss.item()}')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print('Finished Training')\\n\",\n",
    "    \"    return model, tokenizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run training\\n\",\n",
    "    \"trained_model, tokenizer = train_baseline_model('dummy_data.csv')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. ONNX Export & Quantization (The Correct Way)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"from optimum.onnxruntime import ORTQuantizer, ORTModelForSequenceClassification\\n\",\n",
    "    \"from optimum.onnxruntime.configuration import AutoQuantizationConfig\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Simpan dulu model yang sudah dilatih ke sebuah folder\\n\",\n",
    "    \"output_dir = \\\"./siren_model_files\\\"\\n\",\n",
    "    \"trained_model.save_pretrained(output_dir)\\n\",\n",
    "    \"tokenizer.save_pretrained(output_dir)\\n\",\n",
    "    \"print(f\\\"Model dan tokenizer sementara disimpan di {output_dir}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Load model menggunakan ORTModelForSequenceClassification, yang akan meng-handle konversi ke ONNX\\n\",\n",
    "    \"onnx_model = ORTModelForSequenceClassification.from_pretrained(output_dir, export=True)\\n\",\n",
    "    \"print(f\\\"Model berhasil diekspor ke format ONNX.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 3. Buat Quantizer untuk model ONNX tersebut\\n\",\n",
    "    \"quantizer = ORTQuantizer.from_pretrained(onnx_model)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 4. Konfigurasi quantization (AVX2 untuk CPU, tipe dinamis)\\n\",\n",
    "    \"dqconfig = AutoQuantizationConfig.avx2(is_static=False, per_channel=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 5. Lakukan Quantization dan simpan ke DIREKTORI baru\\n\",\n",
    "    \"quantized_model_dir = os.path.join(output_dir, \\\"quantized_model\\\")\\n\",\n",
    "    \"quantizer.quantize(save_dir=quantized_model_dir, quantization_config=dqconfig)\\n\",\n",
    "    \"print(f\\\"Model ONNX berhasil di-quantize dan disimpan di direktori {quantized_model_dir}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 6. Atur path ke file model yang benar di dalam direktori tersebut\\n\",\n",
    "    \"# Nama file defaultnya adalah 'model_quantized.onnx'\\n\",\n",
    "    \"onnx_model_path = os.path.join(quantized_model_dir, \\\"model_quantized.onnx\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Verification\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import onnxruntime\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Siapkan input untuk verifikasi menggunakan tokenizer yang ada\\n\",\n",
    "    \"# \\\"return_tensors='np'\\\" akan membuat input dalam format numpy yang dibutuhkan onnxruntime\\n\",\n",
    "    \"verify_input = tokenizer(\\\"this is a sample url for verification\\\", return_tensors=\\\"np\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Buat ONNX runtime session\\n\",\n",
    "    \"ort_session = onnxruntime.InferenceSession(onnx_model_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Jalankan inference dengan input yang baru dibuat\\n\",\n",
    "    \"ort_outs = ort_session.run(None, dict(verify_input))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('ONNX model loaded and verified successfully!')\\n\",\n",
    "    \"print('Output shape:', ort_outs[0].shape)\\n\",\n",
    "    \"print('Output logits:', ort_outs[0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Download the ONNX Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from google.colab import files\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Download file model ONNX yang sudah di-quantize\\n\",\n",
    "    \"files.download(onnx_model_path)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers pandas torch\n",
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dummy_data.csv file\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_baseline_model(file_path):\n",
    "    # Load Data\n",
    "    df = pd.read_csv(file_path)\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        df['url'], df['is_phishing'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    class PhishingDataset(Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
    "    val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    train_dataset = PhishingDataset(train_encodings, list(train_labels))\n",
    "    val_dataset = PhishingDataset(val_encodings, list(val_labels))\n",
    "\n",
    "    # Model\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Training\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(3):  # 3 epochs for fine-tuning\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1} | Loss: {loss.item()}')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model, tokenizer\n",
    "\n",
    "# Run training\n",
    "trained_model, tokenizer = train_baseline_model('dummy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to CPU for quantization\n",
    "trained_model.to('cpu')\n",
    "\n",
    "# Apply dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    trained_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print('Model successfully quantized.')\n",
    "# You can print the model to see the difference\n",
    "# print(trained_model)\n",
    "# print(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Prepare a dummy input for the exporter\n",
    "dummy_input = tokenizer('this is a sample url', return_tensors='pt')\n",
    "input_ids = dummy_input['input_ids']\n",
    "attention_mask = dummy_input['attention_mask']\n",
    "\n",
    "onnx_model_path = 'siren_model.onnx'\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    quantized_model, \n",
    "    (input_ids, attention_mask), \n",
    "    onnx_model_path, \n",
    "    export_params=True, \n",
    "    opset_version=11, \n",
    "    do_constant_folding=True, \n",
    "    input_names=['input_ids', 'attention_mask'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
    "                  'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
    "                  'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f'Model exported to {onnx_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "# Create an ONNX runtime session\n",
    "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare the dummy input in the format ONNX runtime expects (numpy arrays)\n",
    "ort_inputs = {\n",
    "    'input_ids': input_ids.numpy(),\n",
    "    'attention_mask': attention_mask.numpy()\n",
    "}\n",
    "\n",
    "# Run inference\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print('ONNX model loaded and verified successfully!')\n",
    "print('Output shape:', ort_outs[0].shape)\n",
    "print('Output logits:', ort_outs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download the ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(onnx_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
